# ğŸ“Š Multimodal Explainable AI - Vue d'ensemble complÃ¨te du projet

## ğŸ¯ Vue gÃ©nÃ©rale

**Objectif:** Plateforme Streamlit d'IA explicable pour la classification multimodale (images radiographiques + audio spectrogrammes) avec trois mÃ©thodes XAI (Grad-CAM, LIME, SHAP).

**ProblÃ¨mes rÃ©solus:**
1. âœ… RuntimeError inplace ReLU sur DenseNet121 (SHAP ne compatit pas)
2. âœ… Conflits entre hooks Grad-CAM et SHAP
3. âœ… Support SHAP/LIME pour audio spectrogrammes
4. âœ… StabilitÃ© globale et gestion d'erreurs robuste

---

## ğŸ“ Arborescence complÃ¨te et rÃ´les

```
unified_xai/
â”œâ”€â”€ app.py                          # ğŸ¨ Application Streamlit (UI principale)
â”œâ”€â”€ core/                           # ğŸ”§ Logique centralisÃ©e
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ compatibility.py            # âœ… VÃ©rification compatibilitÃ© XAI
â”‚   â”œâ”€â”€ model_factory.py            # ğŸ­ Fabrique de modÃ¨les SHAP-safe
â”‚   â””â”€â”€ shap_safe_engine.py         # ğŸ›¡ï¸ Moteur SHAP robuste avec fallback
â”œâ”€â”€ image_pipeline/                 # ğŸ–¼ï¸ Pipeline images radiographiques
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py                    # ğŸ“¦ Chargement modÃ¨le image
â”‚   â”œâ”€â”€ preprocess.py               # ğŸ”„ PrÃ©traitement images (224Ã—224, normalisation)
â”‚   â”œâ”€â”€ gradcam.py                  # ğŸ“ Grad-CAM pour images
â”‚   â”œâ”€â”€ lime_image.py               # ğŸ¯ LIME pour images (segmentation SLIC)
â”‚   â””â”€â”€ shap_image.py               # ğŸ’¡ SHAP pour images (utilise engine)
â”œâ”€â”€ audio_pipeline/                 # ğŸµ Pipeline audio spectrogrammes
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py                    # ğŸ“¦ Chargement modÃ¨le audio
â”‚   â”œâ”€â”€ preprocess.py               # ğŸ”„ PrÃ©traitement audio (Mel spectrogram â†’ RGB)
â”‚   â”œâ”€â”€ lime_audio.py               # ğŸ¯ LIME pour audio
â”‚   â””â”€â”€ shap_audio.py               # ğŸ’¡ SHAP pour audio (utilise engine)
â”œâ”€â”€ .gitignore                      # ğŸ“ Exclusions git
â”œâ”€â”€ requirements.txt                # ğŸ“‹ DÃ©pendances (optionnel)
â”œâ”€â”€ validate_shap_integration.py    # âœ… Test du moteur SHAP
â”œâ”€â”€ run_shap_quick.py               # âš¡ Test rapide SHAP
â”œâ”€â”€ check_setup.py                  # ğŸ” VÃ©rifier dÃ©pendances
â”œâ”€â”€ validate_fixes.py               # âœ… Valider tous les fixes
â”œâ”€â”€ diagnose.py                     # ğŸ©º Diagnostic complet
â”œâ”€â”€ CHANGES_SUMMARY.py              # ğŸ“Š RÃ©sumÃ© des changements
â”œâ”€â”€ README.md                       # ğŸ“– Guide utilisateur
â”œâ”€â”€ QUICKSTART.md                   # ğŸš€ DÃ©marrage rapide
â”œâ”€â”€ EXECUTIVE_SUMMARY.md            # ğŸ“‹ RÃ©sumÃ© exÃ©cutif
â”œâ”€â”€ FIXES_DOCUMENTATION.md          # ğŸ”§ Documentation technique
â””â”€â”€ INDEX.json                      # ğŸ“‘ Index du projet
```

---

## ğŸ”— DÃ©pendances et liens entre fichiers

```mermaid
graph TD
    app["app.py<br/>(Streamlit UI)"]
    
    app -->|importe| img_model["image_pipeline/model.py"]
    app -->|importe| img_preprocess["image_pipeline/preprocess.py"]
    app -->|importe| img_gc["image_pipeline/gradcam.py"]
    app -->|importe| img_lime["image_pipeline/lime_image.py"]
    app -->|importe| img_shap["image_pipeline/shap_image.py"]
    
    app -->|importe| aud_model["audio_pipeline/model.py"]
    app -->|importe| aud_preprocess["audio_pipeline/preprocess.py"]
    app -->|importe| aud_lime["audio_pipeline/lime_audio.py"]
    app -->|importe| aud_shap["audio_pipeline/shap_audio.py"]
    
    app -->|importe| core_compat["core/compatibility.py"]
    app -->|importe| core_factory["core/model_factory.py"]
    app -->|importe| core_shap["core/shap_safe_engine.py"]
    
    img_shap -->|utilise| core_shap
    aud_shap -->|utilise| core_shap
    
    img_model -->|utilise| core_factory
    aud_model -->|utilise| core_factory
    
    img_gc -->|crÃ©e hooks| app
    core_shap -->|gÃ¨re hooks| app
```

---

## ğŸ“– Description dÃ©taillÃ©e de chaque fichier

### ğŸ¨ **app.py** â€” Application Streamlit principale

**RÃ´le:** Interface utilisateur, orchestration des pipelines image/audio et XAI.

**Points clÃ©s:**
- Charge images/audio via file uploader
- Affiche prÃ©dictions et confiance
- ExÃ©cute Grad-CAM, LIME, SHAP sur demande
- GÃ¨re le cleanup des hooks pour Ã©viter les conflits

**DÃ©pendances:**
- `streamlit`, `torch`, `torchvision`
- `image_pipeline/*`, `audio_pipeline/*`, `core/*`

**Flux principal:**
```
1. Utilisateur upload image/audio
2. app.py â†’ model.py â†’ charge modÃ¨le (DenseNet/AlexNet)
3. app.py â†’ preprocess.py â†’ normalise input
4. app.py â†’ modÃ¨le â†’ prÃ©diction
5. Utilisateur sÃ©lectionne XAI (Grad-CAM/LIME/SHAP)
6. app.py â†’ (gradcam/lime/shap)_image.py ou audio.py
7. app.py â†’ nettoit les hooks aprÃ¨s chaque XAI
8. app.py â†’ affiche heatmap + mÃ©triques
```

**Erreurs gÃ©rÃ©es:**
- Upload fichier invalide
- ModÃ¨le non trouvÃ©
- Timeout SHAP/LIME
- Conflits hooks Grad-CAM â†” SHAP

---

### ğŸ”§ **core/model_factory.py** â€” Fabrique de modÃ¨les SHAP-safe

**RÃ´le:** CrÃ©er des clones de modÃ¨les avec ReLU inplace remplacÃ©s par ReLU non-inplace.

**Pourquoi:** DenseNet121 utilise ReLU inplace qui casse PyTorch autograd. SHAP a besoin de rÃ©tropropagation : erreur `"element 0 of tensors does not require grad"`.

**Fonctions clÃ©s:**
```python
def _replace_inplace_relu(module):
    """Remplace rÃ©cursivement ReLU(inplace=True) â†’ ReLU(inplace=False)"""
    for name, child in module.named_children():
        if isinstance(child, nn.ReLU) and child.inplace:
            # Remplacer par ReLU non-inplace
        _replace_inplace_relu(child)

def get_shap_safe_model(model_name, model_type='image'):
    """Deep copy + remplace inplace â†’ retourne nouveau modÃ¨le sÃ»r"""
    model = models.densenet121()  # ou autre
    model_clone = copy.deepcopy(model)
    _replace_inplace_relu(model_clone)
    return model_clone
```

**UtilisÃ© par:**
- `image_pipeline/model.py` â†’ charge DenseNet/AlexNet/VGG16
- `audio_pipeline/model.py` â†’ charge ResNet18
- `core/shap_safe_engine.py` â†’ obtient modÃ¨le clÃ´nÃ©

**DÃ©pendances:**
- `torch`, `torchvision`, `copy`

---

### ğŸ›¡ï¸ **core/shap_safe_engine.py** â€” Moteur SHAP robuste

**RÃ´le:** ExÃ©cuter SHAP (DeepExplainer/GradientExplainer) avec fallbacks et gestion d'erreurs.

**ProblÃ¨mes rÃ©solus:**
1. Import TensorFlow manquant â†’ fallback GradientExplainer
2. GradientExplainer Ã©choue â†’ fallback attribution par gradient
3. Tenseurs sans gradients â†’ active temporairement `requires_grad`
4. Conflits avec Grad-CAM â†’ isolation complÃ¨te

**Classe principale: `ShapExplainerEngine`**

```python
class ShapExplainerEngine:
    def __init__(self, model, device="cpu"):
        # Sauvegarde requires_grad original des paramÃ¨tres
        self.orig_requires = None
        
    def explain(self, x_input, background, class_idx=None):
        # 1. Active temporairement requires_grad
        # 2. Tente DeepExplainer â†’ GradientExplainer â†’ gradient fallback
        # 3. Restaure requires_grad original
        # 4. Normalise sortie en heatmap (H, W) [0, 1]
        
    def _model_wrapper(self, x_batch):
        # Wrapper accepte numpy/torch, active requires_grad
        # Retourne sortie modÃ¨le (torch.Tensor ou numpy)
```

**Flux d'explication:**
```
explain(image, background) 
  â†“
Tente DeepExplainer(model_wrapper, background)
  â†“ (ModuleNotFoundError: tensorflow)
Tente GradientExplainer(model_wrapper, background)
  â†“ (Exception)
Calcul gradient manuel: âˆ‚score/âˆ‚input
  â†“
Normalise en heatmap (224, 224)
  â†“
Retourne np.ndarray
```

**UtilisÃ© par:**
- `image_pipeline/shap_image.py`
- `audio_pipeline/shap_audio.py`

**DÃ©pendances:**
- `torch`, `numpy`, `shap` (lazy import)

---

### âœ… **core/compatibility.py** â€” VÃ©rification compatibilitÃ© XAI

**RÃ´le:** Valider que modÃ¨le/tenseurs sont compatibles avec XAI.

**VÃ©rifications:**
- Grad-CAM compatible si modÃ¨le a modules `Conv2d`
- LIME compatible (toujours)
- SHAP compatible si pas de ReLU inplace

**UtilisÃ© par:**
- `app.py` â†’ valide avant d'offrir XAI

---

### ğŸ–¼ï¸ **image_pipeline/model.py** â€” Chargement modÃ¨le image

**RÃ´le:** Charger et initialiser DenseNet121/AlexNet/VGG16.

**ModÃ¨les disponibles:**
- `DenseNet121` (dÃ©faut) â†’ classes radiographiques
- `AlexNet` (legacy)
- `VGG16` (alternative)

**Code clÃ©:**
```python
def load_image_model(model_name='densenet121', num_classes=5):
    if model_name == 'densenet121':
        model = models.densenet121(pretrained=False)
    # Adapter derniÃ¨re couche pour num_classes
    model.classifier = nn.Linear(..., num_classes)
    
    # IMPORTANT: Utiliser model_factory pour SHAP-safety
    from core.model_factory import get_shap_safe_model
    return get_shap_safe_model(model)
```

**UtilisÃ© par:**
- `app.py` â†’ charge au dÃ©marrage et au changement de modÃ¨le

**DÃ©pendances:**
- `torch`, `torchvision`, `core/model_factory.py`

---

### ğŸ”„ **image_pipeline/preprocess.py** â€” PrÃ©traitement image

**RÃ´le:** Redimensionner (224Ã—224), normaliser (ImageNet mean/std), convertir en tensor.

**Pipeline:**
```
Image (H, W, 3) 
  â†“ PIL.Image.resize(224, 224)
  â†“ torchvision.transforms.ToTensor() â†’ (1, 3, 224, 224)
  â†“ Normalisation ImageNet (mean=[0.485, 0.456, 0.406], std=[...])
  â†“ torch.Tensor
```

**Fonction principale:**
```python
def preprocess_image(image_path_or_array, model_name='densenet121'):
    # Charge image PIL
    # Redimensionne 224Ã—224
    # Normalise
    # Retourne torch.Tensor (1, 3, 224, 224)
```

**UtilisÃ© par:**
- `app.py` â†’ avant Grad-CAM/LIME/SHAP

**DÃ©pendances:**
- `torch`, `torchvision.transforms`, `PIL`

---

### ğŸ“ **image_pipeline/gradcam.py** â€” Grad-CAM pour images

**RÃ´le:** GÃ©nÃ©rer heatmap d'activation (localisation classe).

**Algorithme:**
```
1. Enregistrer hook sur derniÃ¨re couche conv
2. Forward pass â†’ capture activations
3. Backward pass sur classe cible
4. Calcul: Î£(âˆ‚score/âˆ‚activation Ã— activation)
5. Normalise en [0, 1]
```

**Fonction principale:**
```python
def generate_gradcam(model, image_tensor, target_class):
    # Configure hooks
    # Forward + backward
    # Calcule heatmap
    # Cleanup hooks
    # Retourne heatmap (224, 224)
```

**Important:** Les hooks doivent Ãªtre supprimÃ©s aprÃ¨s utilisation pour Ã©viter les conflits avec SHAP.

**UtilisÃ© par:**
- `app.py` â†’ onglet Grad-CAM

**DÃ©pendances:**
- `torch`, `cv2`

---

### ğŸ¯ **image_pipeline/lime_image.py** â€” LIME pour images

**RÃ´le:** Explications locales par perturbation et segmentation.

**Algorithme:**
```
1. Segment image en rÃ©gions (SLIC, n_segments=50)
2. CrÃ©er ~200 perturbations (ON/OFF chaque rÃ©gion)
3. PrÃ©dire chaque perturbation
4. RÃ©gression linÃ©aire: importance rÃ©gion
5. Heatmap par fusion des rÃ©gions importantes
```

**Fonction principale:**
```python
def explain_image_lime(model, image, target_class, num_samples=200):
    # Segmente image
    # CrÃ©e perturbations
    # PrÃ©dictions
    # Explainer LIME
    # Retourne heatmap (224, 224)
```

**UtilisÃ© par:**
- `app.py` â†’ onglet LIME

**DÃ©pendances:**
- `lime`, `scikit-image`, `torch`

---

### ğŸ’¡ **image_pipeline/shap_image.py** â€” SHAP pour images

**RÃ´le:** Wrapper SHAP utilisant `ShapExplainerEngine`.

**Code clÃ©:**
```python
def explain_image_shap(model, image_tensor, background_tensors, target_class):
    from core.shap_safe_engine import ShapExplainerEngine
    
    engine = ShapExplainerEngine(model)
    heatmap = engine.explain(image_tensor, background_tensors, class_idx=target_class)
    return heatmap  # (224, 224) numpy array
```

**UtilisÃ© par:**
- `app.py` â†’ onglet SHAP

**DÃ©pendances:**
- `core/shap_safe_engine.py`, `torch`

---

### ğŸµ **audio_pipeline/model.py** â€” Chargement modÃ¨le audio

**RÃ´le:** Charger ResNet18 pour classification spectrogrammes.

**ModÃ¨le:** ResNet18 avec adaptation derniÃ¨re couche.

**Code similaire Ã  `image_pipeline/model.py`:**
```python
def load_audio_model(model_name='resnet18', num_classes=5):
    model = models.resnet18(pretrained=False)
    model.fc = nn.Linear(512, num_classes)
    return get_shap_safe_model(model)  # SHAP-safe
```

**UtilisÃ© par:**
- `app.py` â†’ charge audio model

---

### ğŸ”„ **audio_pipeline/preprocess.py** â€” PrÃ©traitement audio

**RÃ´le:** Convertir audio â†’ Mel spectrogram â†’ RGB image 224Ã—224.

**Pipeline:**
```
Audio (WAV)
  â†“ librosa.load()
  â†“ librosa.feature.melspectrogram()  [n_mels=128, n_fft=2048]
  â†“ NormalisÃ© log-scale dB
  â†“ Redimensionne 224Ã—224
  â†“ Convertit en PIL Image RGB (grayscale â†’ RGB triplÃ©)
  â†“ Normalisation ImageNet
  â†“ torch.Tensor (1, 3, 224, 224)
```

**Fonction principale:**
```python
def preprocess_audio(audio_path, model_name='resnet18'):
    # Charge audio librosa
    # Mel spectrogram
    # Normalise
    # RGB image 224Ã—224
    # Retourne torch.Tensor
```

**UtilisÃ© par:**
- `app.py` â†’ avant audio XAI

**DÃ©pendances:**
- `librosa`, `torch`, `PIL`, `numpy`

---

### ğŸ¯ **audio_pipeline/lime_audio.py** â€” LIME pour audio

**RÃ´le:** LIME sur spectrogrammes audio (mÃªme principe que images).

**Code quasi-identique Ã  `image_pipeline/lime_image.py`:**
```python
def explain_audio_lime(model, audio_spectrogram_tensor, target_class):
    # Segmente spectrogram (SLIC)
    # Perturbe rÃ©gions
    # Explainer LIME
    # Retourne heatmap
```

**UtilisÃ© par:**
- `app.py` â†’ onglet LIME audio

---

### ğŸ’¡ **audio_pipeline/shap_audio.py** â€” SHAP pour audio

**RÃ´le:** SHAP sur spectrogrammes utilisant `ShapExplainerEngine`.

**Code identique Ã  `image_pipeline/shap_image.py`:**
```python
def explain_audio_shap(model, spectrogram_tensor, background_tensors, target_class):
    from core.shap_safe_engine import ShapExplainerEngine
    
    engine = ShapExplainerEngine(model)
    heatmap = engine.explain(spectrogram_tensor, background_tensors, class_idx=target_class)
    return heatmap
```

**UtilisÃ© par:**
- `app.py` â†’ onglet SHAP audio

---

## ğŸ§ª Scripts de validation et diagnostic

### âœ… **validate_shap_integration.py** â€” Test du moteur SHAP

**Objectif:** VÃ©rifier que `ShapExplainerEngine` fonctionne sans erreur autograd.

**Code:**
```python
from core.shap_safe_engine import ShapExplainerEngine
import torch
import torch.nn as nn

class DummyModel(nn.Module):
    def forward(self, x): return self.fc(self.pool(torch.relu(self.conv(x))))

model = DummyModel()
engine = ShapExplainerEngine(model)
x = torch.randn(1, 3, 224, 224)
bg = torch.randn(2, 3, 224, 224)
heat = engine.explain(x, bg, class_idx=0)
print(f"Heatmap shape: {heat.shape}")  # (224, 224)
```

**ExÃ©cution:** `python validate_shap_integration.py`

**Attendu:** Pas d'erreur autograd, heatmap (224, 224) retournÃ©e.

---

### âš¡ **run_shap_quick.py** â€” Test rapide SHAP

**Objectif:** Test rapide du wrapper `_model_wrapper`.

**ExÃ©cution:** `python run_shap_quick.py`

---

### ğŸ” **check_setup.py** â€” VÃ©rifier dÃ©pendances

**Objectif:** Valider installation de torch, torchvision, shap, streamlit, etc.

**ExÃ©cution:** `python check_setup.py`

**Affiche:** âœ“ ou âœ— pour chaque dÃ©pendance.

---

### âœ… **validate_fixes.py** â€” Valider tous les fixes

**Objectif:** ExÃ©cuter une suite complÃ¨te de tests :
- Import modules
- Chargement modÃ¨les SHAP-safe
- ExÃ©cution Grad-CAM, LIME, SHAP
- VÃ©rification heatmaps

**ExÃ©cution:** `python validate_fixes.py`

---

### ğŸ©º **diagnose.py** â€” Diagnostic complet

**Objectif:** Inspection dÃ©taillÃ©e systÃ¨me, modÃ¨les, dÃ©pendances.

**ExÃ©cution:** `python diagnose.py`

---

### ğŸ“Š **CHANGES_SUMMARY.py** â€” RÃ©sumÃ© changements

**Objectif:** Lister fichiers modifiÃ©s/ajoutÃ©s et leur rÃ´le.

**ExÃ©cution:** `python CHANGES_SUMMARY.py`

---

## ğŸ“Š Matrice de dÃ©pendances

| Fichier | DÃ©pend de | UtilisÃ© par |
|---------|-----------|------------|
| `app.py` | Tous | - |
| `core/model_factory.py` | torch, copy | image/audio model.py, shap_engine |
| `core/shap_safe_engine.py` | torch, numpy, shap | shap_image.py, shap_audio.py |
| `core/compatibility.py` | torch | app.py |
| `image_pipeline/model.py` | model_factory | app.py |
| `image_pipeline/preprocess.py` | torch, PIL, torchvision | app.py |
| `image_pipeline/gradcam.py` | torch, cv2 | app.py |
| `image_pipeline/lime_image.py` | lime, torch | app.py |
| `image_pipeline/shap_image.py` | shap_safe_engine | app.py |
| `audio_pipeline/model.py` | model_factory | app.py |
| `audio_pipeline/preprocess.py` | librosa, torch, PIL | app.py |
| `audio_pipeline/lime_audio.py` | lime, torch | app.py |
| `audio_pipeline/shap_audio.py` | shap_safe_engine | app.py |

---

## ğŸš€ Flux utilisateur complet

```
Utilisateur ouvre Streamlit
  â†“
app.py init()
  â”œâ”€ load_image_model() â†’ utilise model_factory â†’ DenseNet SHAP-safe
  â””â”€ load_audio_model() â†’ utilise model_factory â†’ ResNet18 SHAP-safe

Utilisateur upload IMAGE
  â†“
app.py: preprocess_image() â†’ torch.Tensor (1, 3, 224, 224)
  â†“
app.py: modÃ¨le(input) â†’ prÃ©diction + classe
  â†“
Utilisateur clique "Grad-CAM"
  â”œâ”€ image_pipeline/gradcam.py â†’ hook + backward
  â”œâ”€ _cleanup_hooks() â†’ enlÃ¨ve hooks
  â””â”€ Affiche heatmap

Utilisateur clique "LIME"
  â”œâ”€ image_pipeline/lime_image.py
  â”œâ”€ SLIC segmentation
  â”œâ”€ Perturbations
  â””â”€ Affiche heatmap

Utilisateur clique "SHAP"
  â”œâ”€ image_pipeline/shap_image.py
  â”œâ”€ ShapExplainerEngine.explain()
  â”‚  â”œâ”€ Tente DeepExplainer (TensorFlow)
  â”‚  â”œâ”€ Fallback GradientExplainer
  â”‚  â””â”€ Fallback gradient manuel
  â””â”€ Affiche heatmap

Utilisateur upload AUDIO
  â†“
app.py: preprocess_audio() â†’ Mel spectro â†’ RGB image
  â†“
(MÃªme flux que images mais audio_pipeline/)
```

---

## ğŸ”§ ProblÃ¨mes et solutions

| ProblÃ¨me | Fichier | Solution |
|----------|---------|----------|
| DenseNet ReLU inplace | `core/model_factory.py` | Deep clone + remplace rÃ©cursivement |
| Grad-CAM â†” SHAP hooks | `app.py` | Cleanup systÃ©matique aprÃ¨s chaque XAI |
| SHAP autograd "no grad" | `core/shap_safe_engine.py` | Active requires_grad temporairement |
| TensorFlow manquant | `core/shap_safe_engine.py` | Lazy import + fallback GradientExplainer |
| Pas de SHAP audio | `audio_pipeline/shap_audio.py` | Utilise engine avec spectrogrammes |
| Audio format incompatible | `audio_pipeline/preprocess.py` | Mel spectrogram â†’ RGB 224Ã—224 |

---

## ğŸ“ˆ Performance attendue

| OpÃ©ration | Temps |
|-----------|-------|
| PrÃ©diction | ~0.5s |
| Grad-CAM | ~1-2s |
| LIME | ~8-15s |
| SHAP (DeepExplainer) | ~15-30s |
| SHAP (fallback gradient) | ~3-5s |
| Onglet comparaison | ~30-60s |

---

## âœ… Ã‰tat du projet

- [x] Correction ReLU inplace (model_factory)
- [x] Grad-CAM isolation (cleanup hooks)
- [x] SHAP safe engine (deep clone + fallback)
- [x] Audio LIME/SHAP support
- [x] Validation scripts
- [x] Documentation complÃ¨te
- [x] GitHub push (propre avec .gitignore)

**Status:** âœ… Production-ready

---

## ğŸ“‹ Checklist dÃ©ploiement

```bash
# 1. Installer dÃ©pendances
pip install torch torchvision torchaudio librosa lime shap numpy PIL streamlit

# 2. (Optionnel) Installer TensorFlow pour DeepExplainer
pip install tensorflow

# 3. Valider setup
python check_setup.py

# 4. Lancer app
streamlit run app.py

# 5. Visiter http://localhost:8501
```

---

## ğŸ”— Liens clÃ©s fichiers

**SHAP Flow:**
```
app.py 
  â†’ image_pipeline/shap_image.py 
    â†’ core/shap_safe_engine.py 
      â†’ _model_wrapper() + engine.explain()
```

**Grad-CAM Flow:**
```
app.py
  â†’ image_pipeline/gradcam.py
    â†’ Hook + backward
    â†’ app._cleanup_hooks()
```

**LIME Flow:**
```
app.py
  â†’ image_pipeline/lime_image.py
    â†’ SLIC segmentation
    â†’ Perturbations
    â†’ Explainer LIME
```

**Model Loading:**
```
app.py
  â†’ image_pipeline/model.py
    â†’ core/model_factory.py (SHAP-safe)
    â†’ returns: DenseNet121 sans inplace ReLU
```

---

**CrÃ©Ã©:** 7 janvier 2026  
**Auteur:** Assistant AI  
**Statut:** âœ… Complet et fonctionnel
